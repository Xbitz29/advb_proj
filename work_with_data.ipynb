{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "loc = pd.read_csv('loc.csv', sep=\";\")\n",
    "prod = pd.read_csv('prod.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/lv_fvvc97912rlw1b4267t8h0000gn/T/ipykernel_11668/4076915570.py:4: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  train.loc[:, 'location_id'] = train['location_id'].apply(lambda x: int(x))\n",
      "/var/folders/h9/lv_fvvc97912rlw1b4267t8h0000gn/T/ipykernel_11668/4076915570.py:5: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  train.loc[:, 'product_id'] = train['product_id'].apply(lambda x: int(x))\n"
     ]
    }
   ],
   "source": [
    "train = train[train['product_id'].isna() != True]\n",
    "train = train[train['location_id'].isna() != True]\n",
    "train = train[train['PRICE_AFTER_DISC'].isna() != True]\n",
    "train.loc[:, 'location_id'] = train['location_id'].apply(lambda x: int(x))\n",
    "train.loc[:, 'product_id'] = train['product_id'].apply(lambda x: int(x))\n",
    "merge_train = train[['demand', 'PROMO1_FLAG',\n",
    "       'PROMO2_FLAG', 'PRICE_REGULAR', 'PRICE_AFTER_DISC', 'NUM_CONSULTANT',\n",
    "       'AUTORIZATION_FLAG', 'id']]\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(merge_train, how='left', on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Избавились от колонок с NaN\n",
    "loc = loc.drop(columns=['STORE_OPEN_DTTM', 'STORE_CLOSURE_DTTM'])\n",
    "prod = prod.drop(columns=['SALES_INTRODUCTION_DT', 'SALES_DISCONTINUED_DT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.rename(columns={'STORE_LOCATION_RK':'location_id'}, inplace=True)\n",
    "prod.rename(columns={'PRODUCT_RK':'product_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train = train.merge(loc, how='left', on='location_id')\n",
    "real_train = real_train.merge(prod, how='left', on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = test.merge(loc, how='left', on='location_id')\n",
    "real_test = real_test.merge(prod, how='left', on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = real_test.drop(columns = ['demand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_columns_lists = []\n",
    "for i in real_train.columns:\n",
    "    if len(real_train[i].unique()) == 1:\n",
    "        bad_columns_lists.append(i)\n",
    "\n",
    "real_train.drop(columns=bad_columns_lists, inplace=True)\n",
    "real_test.drop(columns=bad_columns_lists, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(df, date_column):\n",
    "    transformed_df = df.copy()\n",
    "\n",
    "    transformed_df[date_column] = pd.to_datetime(transformed_df[date_column])\n",
    "\n",
    "    transformed_df['day'] = transformed_df[date_column].dt.day\n",
    "    transformed_df['month'] = transformed_df[date_column].dt.month\n",
    "    transformed_df['year'] = transformed_df[date_column].dt.year\n",
    "    transformed_df['day_of_week'] = transformed_df[date_column].dt.weekday\n",
    "    \n",
    "    transformed_df.drop(date_column, axis=1, inplace=True)\n",
    "\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = transform_dataframe(real_train, 'period_dt')\n",
    "test_data = transform_dataframe(real_test, 'period_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dt_df(df, column = 'VALID_FROM_DTTM_y'):\n",
    "    transformed_df = df.copy()\n",
    "\n",
    "    transformed_df[column] = pd.to_datetime(transformed_df[column], format=\"%d%b%Y:%H:%M:%S\")\n",
    "\n",
    "    transformed_df[column + '_day'] = transformed_df[column].dt.day\n",
    "    transformed_df[column + '_month'] = transformed_df[column].dt.month\n",
    "    transformed_df[column + '_year'] = transformed_df[column].dt.year\n",
    "    transformed_df[column + '_hour'] = transformed_df[column].dt.hour\n",
    "    transformed_df[column + '_minute'] = transformed_df[column].dt.minute\n",
    "    transformed_df[column + '_second'] = transformed_df[column].dt.second\n",
    "    transformed_df[column + '_weekday'] = transformed_df[column].dt.weekday\n",
    "\n",
    "    transformed_df.loc[transformed_df[column + '_year'] > 2260, [column + '_day', column + '_month', column + '_year']] = [1, 1, 2260]\n",
    "\n",
    "    transformed_df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = transform_dt_df(train_data)\n",
    "test_data = transform_dt_df(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим процент от начальной цены\n",
    "train_data.loc[:, 'disc_percent'] = train_data['PRICE_AFTER_DISC'] / train_data['PRICE_REGULAR']\n",
    "test_data.loc[:, 'disc_percent'] = test_data['PRICE_AFTER_DISC'] / test_data['PRICE_REGULAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средние значения ответа\n",
    "group_all = train_data[['month', 'location_id', 'demand']].groupby(by=['month', 'location_id'], as_index=False).mean()\n",
    "group_date = train_data[['month', 'demand']].groupby(by=['month'], as_index=False).mean()\n",
    "train_data = train_data.merge(group_all, on=['month', 'location_id'], how='left', suffixes=('', '_all'))\n",
    "test_data = test_data.merge(group_all, on=['month', 'location_id'], how='left', suffixes=('', '_all'))\n",
    "train_data = train_data.merge(group_date, on=['month'], how='left', suffixes=('', '_new'))\n",
    "test_data = test_data.merge(group_date, on=['month'], how='left', suffixes=('', '_new'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим номер недели с начала продажи товара\n",
    "train_data = train_data.sort_values(by=['year', 'month', 'day'])\n",
    "tmp = train_data.groupby(by=['location_id', 'product_id'], as_index=False).cumcount() + 1\n",
    "train_data.loc[:, 'number_of_week'] = tmp\n",
    "test_data = test_data.sort_values(by=['year', 'month', 'day'])\n",
    "tmp = test_data.groupby(by=['location_id', 'product_id'], as_index=False).cumcount() + 1\n",
    "test_data.loc[:, 'number_of_week'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train.to_csv('/Users/ilyas/CS/third_year/ADVB/project/train_add.csv', index=False)\n",
    "real_test.to_csv('/Users/ilyas/CS/third_year/ADVB/project/test_add.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
